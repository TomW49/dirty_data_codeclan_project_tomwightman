---
title: "Documentation: task_4_halloween_candy"
output:
  html_document: 
    number_sections: no
    toc: yes
    df_print: paged
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

By Tom Wightman

# Introduction

The `clean_halloween_candy_2015_to_2017.csv` data set is comprised of three original data sets:

-   `boing-boing-candy-2015.xlsx`
-   `boing-boing-candy-2016.xlsx`
-   `boing-boing-candy-2017.xlsx`

These data sets are based on collected data from annual surveys between 2015 and 2017 using Googlesheets, and what looks like an organisations internal survey, gaining responses from just under 10,000 people over the time period.

The surveys them self ask the users to rate their opinion on several "candy" types using a rating of either "JOY", "MEH" or "DESPAIR", however there are a number of discrepancies between each data set. In 2015, the "MEH" response was missing for the users, in addition to spelling errors leading to duplicate inputs - standardization was not a high priority of the creators!

More information of the data sets can be found [here](https://www.scq.ubc.ca/so-much-candy-data-seriously/).

Below is an infograpgh brining the data to life in a quirky yet informative fashion.

![](https://boingboing.net/wp-content/uploads/2017/10/candyhierarchy2017-1.jpg)

# Assumptions

Some of the assumptions I made during the cleaning and analysis phase of the data are as follows:

-   The lowest age to be included in the data was 4, as I thought that parents/guardians could theoretically ask them if they like, really like, or hate specific candy. In reality however I doubt this would ever be the case, as a 4 year old would hopefully never be exposed to that much candy in their short lifespan.
-   The highest age to be included in the data was 100, as this seems now to be a reasonable age to reach, and still be able to answer a list of questions about candy - my granny actually lived to 101!
-   I also included NA's within the data sets, as this could prove to be useful data - a lot of NA's had additional data to them, so removing them would have taken away a lot of information.
-   I had removed all non-edible items, including medication, as I wanted a smaller data set for potential returns in runtimes and a cleaner look. I did this based on the questions presented to me, all specific about "candy" and "candy bars", not "what is your favourite font" and "vicodin" (paracetamol). I do recognise that "cash or other forms of legal tender" is a fair item to be given during Halloween (maybe in a wealthy neighborhood), however again using the questions as basis for cleaning I removed it.

# Cleaning

### Reading in the data

I used `tidyverse` and `janitor` packages to read in and clean the variable names in addition to using `here` package to aid reproducability.

### Cleaning `boing-boing-candy-2015.xlsx`

I chose to pivot all of the data sets in long format for ease of wrangling and manipulation.

I used the below code to remove the "timestamp" variable and replace it with the year in order to identify when joining all three data sets. I also renamed two columns in order to better accommodate the join.

```{r, eval = FALSE}
pivot_prep_candy15 <- bbcandy2015 %>%   
  select(-timestamp) %>%    
  rename(going_out = are_you_going_actually_going_trick_or_treating_yourself, 
               age = how_old_are_you) %>%      
  add_column(year  = 2015, .before = 1)
```

I then pivoted the prepared data above using:

```{r, eval = FALSE}
pivot_candy15 <- pivot_prep_candy15 %>% 
    pivot_longer(cols = 4:124, 
                 names_to = "candy", 
                 values_to = "reaction")
```

I continued programming this to remove all self identified non-edible variables including medication. The list can be seen in the `cleaning_script_task4_halloween_candy.csv`

### Cleaning `boing-boing-candy-2016.xlsx`

Again a similar process to the above with slight changes in order to facilitate the merging of all data sets later.

```{r, eval = FALSE}
pivot_prep_candy16 <- bbcandy2016 %>%
  select(-timestamp) %>% 
  rename(going_out  = are_you_going_actually_going_trick_or_treating_yourself,
         age        = how_old_are_you,
         gender     = your_gender,
         country    = which_country_do_you_live_in,
         province   = which_state_province_county_do_you_live_in) %>%   
  add_column(year = 2016, .before = 1) 
```

The pivot of the data had the same process as 2015's pivot code, however it had additional values I wanted to remove such as "person_of_interest_season_3\_dvd_box_set_not_including_disc_4\_with_hilarious_outtakes".

### Cleaning `boing-boing-candy-2017.xlsx`

For 2017 data, I noticed that there had been a prefix of "Q" then relative numbers to the variables, with "Q6" repeating itself. The below code removes that on all variables, using regex to look for a lowercase q at the beginning of the name, followed by a number and any amount of characters in addition to an underscore:

```{r, eval = FALSE}
names(bbcandy2017) = gsub(pattern = "^q[0-9]*_", replacement = "", 
                          x = names(bbcandy2017))
```

I then used the same process as for the other years to prepare data set for a pivot. I also renamed "anonymous_brown...." to mary_janes in order for that data to match with the other tables to give more accurate analysis.

```{r, eval = FALSE}
pivot_prep_candy17 <- bbcandy2017 %>%
  select(-c(internal_id, 110:120)) %>% 
  rename(province    = state_province_county_etc,
         mary_janes  = anonymous_brown_globs_that_come_in_black_and_orange_wrappers_a_k_a_mary_janes) %>%   
  add_column(year = 2017, .before = 1) 
```

### Combining cleaned data sets and further cleaning

When I had combined them, I realised that I had missed some duplicates and errors. The below code enables more standardisation and more accurate results. I also used this oppurtunity to re-order the columns for ease of use.

```{r, eval = FALSE}
# joining all three cleaned datasets
candy_combined <- bind_rows(pivot_candy15, 
                            pivot_candy16, 
                            pivot_candy17) %>% 
  select(1,3,6,2,7,8, everything())

# cleaning further spelling errors for standardisation 
candy_combined <- candy_combined%>% 
  mutate(candy = case_when(
    candy == "boxo_raisins" ~ "box_o_raisins",
    candy == "sweetums_a_friend_to_diabetes" ~ "sweetums",
    candy == "anonymous_brown_globs_that_come_in_black_and_orange_wrappers" ~ "mary_janes",
    TRUE ~ candy)) 
```

I then had to create a pattern to identify the United Kingdom and the United States of America and replace them with a desired value. This was achieved by grouping the countries and extracting them as a list using `pull()`. I then had to delete countries in my list that I believed did not identify as the United States of America, and separate them with the `|` logical operator. I used this process for the United Kingdom also. Some specific country values were either not caught, or caught in a "usa" or "uk" process, therefore manual placement had to be made.

I then used the below code to carry out the "re-coding":

```{r, eval = FALSE}
# lowering case of country, recoding uk, usa, canada and other data country data only
candy_combined <-  candy_combined %>% 
  mutate(country = str_to_lower(country)) %>% 
  mutate(country = case_when(
    str_detect(country, "not[\\s]{1,}") ~ "other",
    str_detect(country, "australia") ~ "other",
    str_detect(country, "austria") ~ "other",
    str_detect(country, "soviet canuckistan") ~ "other",
    str_detect(country, "subscribe to dm4uz3 on youtube") ~ "other",
    str_detect(country, str_c(usa_pattern, collapse = "|")) ~ "usa",
    str_detect(country, str_c(uk_pattern, collapse = "|")) ~ "uk",
    str_detect(country, "^can") ~ "canada",
    is.na(country) == TRUE ~ "other",
    TRUE ~ "other")
  ) 
```

Lastly, the age column had to be cleaned as it was in character format and also held unrealistic ages of 0 years and 500+ years old.

```{r, eval = FALSE}
# cleaning age column, turning into integer for manipulation 
# using data only from 4 to 100 year olds
candy_combined <- candy_combined %>%
  mutate(age = as.integer(age)) %>% 
  mutate(age = ifelse(age <= 100, age, NA_integer_)) %>% 
  mutate(age = ifelse(age >= 4, age, NA_integer_)) %>% 
  drop_na(age) 
```

# Analysis

The questions to be answered from the project are as follows:

### 1. What is the total number of candy ratings given across the three years. (number of candy ratings, not number of raters. Don't count missing values)

There was a total of 640451 ratings provided of either "JOY", "MEH" or "DESPAIR".

I did find that the number of NA's, 115079, was a fairly large amount of unused ratings. A portion of these are due to some candy's not being included in the other annual data sets, therefore being converted to NA's.

### 2. What was the average age of people who are going out trick or treating and the average age of people not going trick or treating?

The average age of people going trick or treating is 35. The average age of people not going trick or treating is 39.

It is interesting to see that the average age of people going out trick or treating is 35; this would make sense in my opinion as it would normally be the parents of children going out on Halloween in order to look after them. Also, I don't believe children would be interested of have access to a questionnaire such as this.

The data also showed that the majority of people tended to stop going out trick or treating at 39, potentially showing on average a 4 year period where adults take their children out.

### 3. For each of joy, despair and meh, which candy bar received the most of these ratings?

An important factor to consider is that in the 2015 data there was no "MEH" variable for the users to select, so data may be unbalanced,

-   "JOY" - Any full sized candy bar
-   "MEH" - Lollipops
-   "DESPAIR" - Mary Janes

I would say that these results fall in line with my own opinions.

### 4. How many people rated Starburst as despair?

1864. As it says on the tin.

### 5. What was the most popular candy bar by this rating system for each gender in the dataset?

For this and the next two questions, I counted DESPAIR as -1, JOY as +1 and MEH as 0.

The most popular candy bar was males was "Any full sized candy bar", with a count of 1533.

The most popular candy bar was females was "Any full sized candy bar", with a count of 855.

### 6. What was the most popular candy bar in each year?

-   2015 - "Any full sized candy bar", with a count of 4392.
-   2016 - "Any full sized candy bar", with a count of 982.
-   2017 - "Any full sized candy bar", with a count of 1497.

I think I see a pattern here...

### 7. What was the most popular candy bar by this rating for people in US, Canada, UK and all other countries?

-   US - "Any full sized candy bar", with a count of 2122.
-   Canada - "Any full sized candy bar", with a count of 248.
-   UK - "Any full sized candy bar", with a count of 33 (also matched with "Lindt Truffle, Rolos and Toblerone).
-   Other - "Any full sized candy bar", with a count of 4468.

# Conclusions

Through reading more information on the data sets and interrogating other users analyses, it was interesting to see that "cash or other forms of legal tender" rated number 1 rated item for people from the United Kingdom - I had removed this from my data.

It was also interesting to see that the average age of people going out trick or treating was 35; this would make sense in my opinion as mentioned before this would be normally the parents of children going out on Halloween.

The data also showed that the majority of people tended to stop going out trick or treating at 39, potentially showing on average a 4 year period where adults take their children out.
